{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56f89afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END \n",
    "from typing import TypedDict, List\n",
    "from langchain_core.documents import Document\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "173e4422",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv(\"E:\\\\AI-Buildathon\\\\.env\")\n",
    "api_key = os.getenv(\"GOOGLE_GENAI_API_KEY\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86979275",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.7, api_key=api_key)\n",
    "\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81c36bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\pytho3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 9 0 (offset 0)\n",
      "Ignoring wrong pointing object 11 0 (offset 0)\n",
      "Ignoring wrong pointing object 27 0 (offset 0)\n",
      "Ignoring wrong pointing object 76 0 (offset 0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2031"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader, UnstructuredPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "def load_pdf_documents(file_path):\n",
    "    loader = DirectoryLoader(\n",
    "    file_path,\n",
    "    glob=\"**/*.pdf\",\n",
    "    loader_cls=PyPDFLoader,\n",
    "\n",
    ")\n",
    "    \n",
    "    documents=loader.load()\n",
    "    return documents\n",
    "\n",
    "document=load_pdf_documents(\"E:\\\\AI-Buildathon\\\\data\")\n",
    "\n",
    "len(document)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49764986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced metadata mapping based on actual file names\n",
    "source_mapping = {\n",
    "    \"9789241505550_eng.pdf\": {\"source\": \"WHO\", \"type\": \"Clinical Guidelines\"},\n",
    "    \"brb-mn-21-01-guideline-2017-eng-guidelines-for-antenatal-care-in-barbados-revised-feb-2017.pdf\": {\"source\": \"Barbados Ministry of Health\", \"type\": \"Antenatal Care Guidelines\"},\n",
    "    \"dokumen.pub_the-pregnancy-encyclopedia-9780241660119-9780241731628.pdf\": {\"source\": \"Pregnancy Encyclopedia\", \"type\": \"Comprehensive Reference\"},\n",
    "    \"Exclusive-breastfeeding-guide-2022_1-August.pdf\": {\"source\": \"Breastfeeding Authority\", \"type\": \"Breastfeeding Guide\"},\n",
    "    \"Maternal Nutrition UNICEF.pdf\": {\"source\": \"UNICEF\", \"type\": \"Nutrition Guidelines\"},\n",
    "    \"pregnancy-and-childbirth-expecting-a-baby-pregnancy-guide-pregnancy-what-to-expect-pregnancy-health-pregnancy-eating-and-recipes.pdf\": {\"source\": \"Pregnancy Health Guide\", \"type\": \"Patient Education\"},\n",
    "    \"WHO.pdf\": {\"source\": \"WHO\", \"type\": \"General Guidelines\"},\n",
    "    \"who_postnatal.pdf\": {\"source\": \"WHO\", \"type\": \"Postnatal Care Guidelines\"}\n",
    "}\n",
    "\n",
    "for doc in document:\n",
    "    # Get source and handle both string and list types\n",
    "    source = doc.metadata.get(\"source\", \"\")\n",
    "    \n",
    "    # If source is a list, take the first element\n",
    "    if isinstance(source, list):\n",
    "        source = source[0] if source else \"\"\n",
    "    \n",
    "    # Extract filename from full path\n",
    "    if source:\n",
    "        filename = source.split(\"\\\\\")[-1]\n",
    "    else:\n",
    "        filename = \"\"\n",
    "    \n",
    "    source_info = source_mapping.get(filename, {\"source\": \"Unknown\", \"type\": \"General\"})\n",
    "    \n",
    "    doc.metadata.update({\n",
    "        \"source\": source_info[\"source\"],\n",
    "        \"document_type\": source_info[\"type\"],\n",
    "        \"filename\": filename,\n",
    "        \"region\": \"Global/Bangladesh\",\n",
    "        \"language\": \"en\",\n",
    "        \"confidence_level\": \"primary\",\n",
    "        \"domain\": \"maternal_health\"\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2532b8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Chunks: 6457\n",
      "Average Chunk Size: 640 characters\n"
     ]
    }
   ],
   "source": [
    "def text_splitter(documents):\n",
    "    # Optimized for medical/clinical content with semantic boundaries\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=800,  # Smaller chunks for better precision\n",
    "        chunk_overlap=200,  # More overlap to preserve context\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \". \", \", \", \" \", \"\"],  # Preserve sentence boundaries\n",
    "        is_separator_regex=False,\n",
    "    )\n",
    "    text_chunk = text_splitter.split_documents(documents)\n",
    "    \n",
    "    # Add chunk metadata for better tracking\n",
    "    for i, chunk in enumerate(text_chunk):\n",
    "        chunk.metadata['chunk_id'] = i\n",
    "        chunk.metadata['chunk_size'] = len(chunk.page_content)\n",
    "    \n",
    "    return text_chunk\n",
    "\n",
    "text_chunk = text_splitter(document)\n",
    "print(f\"Number of Chunks: {len(text_chunk)}\")\n",
    "print(f\"Average Chunk Size: {sum(c.metadata['chunk_size'] for c in text_chunk) / len(text_chunk):.0f} characters\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d82e6d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58437b8e237c42349d501463503eb8e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pytho3\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\acer\\.cache\\huggingface\\hub\\models--BAAI--bge-base-en-v1.5. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31ee8caac7434d8997c55182268aa38e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c191d897c10e45ee85b199f90e3ba456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0362feee71f49029b7b7ebf5c0cd5a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0c839e377c547da9f2ff21cee326d0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/777 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2128b3348c814140bffbf632365d6b17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63d5629d4bfb4500875777516d6dbb90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08b4983d3b5641d589aea3f68ed11e56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8beb3d2cf01346dfa2eee63320924539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70fd28356af04d6bb7c0ae14e4467236",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74264adbba624e9ea52a170981357c7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Using embedding model that matches your Pinecone index dimension (384)\n",
    "# Your current index \"test\" was created with 384 dimensions\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",  # 384 dimensions - matches your index\n",
    "    model_kwargs={'device': 'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")\n",
    "\n",
    "# To use better models (768 dim), you'll need to:\n",
    "# 1. Delete or create a new Pinecone index with dimension=768\n",
    "# 2. Then switch to one of these models:\n",
    "#    - \"BAAI/bge-base-en-v1.5\" - Best retrieval performance\n",
    "#    - \"sentence-transformers/all-mpnet-base-v2\" - Better semantic understanding\n",
    "#    - \"sentence-transformers/multi-qa-mpnet-base-dot-v1\" - Optimized for Q&A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1eae6035",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\"E:\\\\AI-Buildathon\\\\.env\")\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "869d1639",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "index = pc.Index(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db5fd0e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "PineconeApiException",
     "evalue": "(400)\nReason: Bad Request\nHTTP response headers: HTTPHeaderDict({'Date': 'Sun, 28 Dec 2025 16:12:42 GMT', 'Content-Type': 'application/json', 'Content-Length': '102', 'Connection': 'keep-alive', 'x-pinecone-request-latency-ms': '1664', 'x-pinecone-request-id': '3479094119580190069', 'x-envoy-upstream-service-time': '32', 'x-pinecone-response-duration-ms': '1666', 'server': 'envoy'})\nHTTP response body: {\"code\":3,\"message\":\"Vector dimension 768 does not match the dimension of the index 384\",\"details\":[]}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPineconeApiException\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_pinecone\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PineconeVectorStore\n\u001b[1;32m----> 3\u001b[0m docstore \u001b[38;5;241m=\u001b[39m \u001b[43mPineconeVectorStore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_chunk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\pytho3\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:813\u001b[0m, in \u001b[0;36mVectorStore.from_documents\u001b[1;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[0;32m    810\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ids):\n\u001b[0;32m    811\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ids\n\u001b[1;32m--> 813\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\pytho3\\Lib\\site-packages\\langchain_pinecone\\vectorstores.py:978\u001b[0m, in \u001b[0;36mPineconeVectorStore.from_texts\u001b[1;34m(cls, texts, embedding, metadatas, ids, batch_size, text_key, namespace, index_name, upsert_kwargs, pool_threads, embeddings_chunk_size, async_req, id_prefix, **kwargs)\u001b[0m\n\u001b[0;32m    975\u001b[0m pinecone_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mget_pinecone_index(index_name, pool_threads)\n\u001b[0;32m    976\u001b[0m pinecone \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(pinecone_index, embedding, text_key, namespace, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 978\u001b[0m \u001b[43mpinecone\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_chunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings_chunk_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43masync_req\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masync_req\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    986\u001b[0m \u001b[43m    \u001b[49m\u001b[43mid_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mid_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    987\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mupsert_kwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    988\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    989\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pinecone\n",
      "File \u001b[1;32md:\\pytho3\\Lib\\site-packages\\langchain_pinecone\\vectorstores.py:370\u001b[0m, in \u001b[0;36mPineconeVectorStore.add_texts\u001b[1;34m(self, texts, metadatas, ids, namespace, batch_size, embedding_chunk_size, async_req, id_prefix, **kwargs)\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m async_req:\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;66;03m# Runs the pinecone upsert asynchronously.\u001b[39;00m\n\u001b[0;32m    361\u001b[0m     async_res \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mupsert(\n\u001b[0;32m    363\u001b[0m             vectors\u001b[38;5;241m=\u001b[39mbatch_vector_tuples,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m batch_vector_tuples \u001b[38;5;129;01min\u001b[39;00m batch_iterate(batch_size, vector_tuples)\n\u001b[0;32m    369\u001b[0m     ]\n\u001b[1;32m--> 370\u001b[0m     [\u001b[43mres\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m async_res]\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    372\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mupsert(\n\u001b[0;32m    373\u001b[0m         vectors\u001b[38;5;241m=\u001b[39mvector_tuples,\n\u001b[0;32m    374\u001b[0m         namespace\u001b[38;5;241m=\u001b[39mnamespace,\n\u001b[0;32m    375\u001b[0m         async_req\u001b[38;5;241m=\u001b[39masync_req,\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    377\u001b[0m     )\n",
      "File \u001b[1;32md:\\pytho3\\Lib\\multiprocessing\\pool.py:774\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[0;32m    773\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 774\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[1;32md:\\pytho3\\Lib\\multiprocessing\\pool.py:125\u001b[0m, in \u001b[0;36mworker\u001b[1;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[0;32m    123\u001b[0m job, i, func, args, kwds \u001b[38;5;241m=\u001b[39m task\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 125\u001b[0m     result \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wrap_exception \u001b[38;5;129;01mand\u001b[39;00m func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _helper_reraises_exception:\n",
      "File \u001b[1;32md:\\pytho3\\Lib\\site-packages\\pinecone\\openapi_support\\api_client.py:182\u001b[0m, in \u001b[0;36mApiClient.__call_api\u001b[1;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m PineconeApiException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    181\u001b[0m     e\u001b[38;5;241m.\u001b[39mbody \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mbody\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 182\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_response \u001b[38;5;241m=\u001b[39m response_data\n\u001b[0;32m    186\u001b[0m return_data \u001b[38;5;241m=\u001b[39m response_data\n",
      "File \u001b[1;32md:\\pytho3\\Lib\\site-packages\\pinecone\\openapi_support\\api_client.py:170\u001b[0m, in \u001b[0;36mApiClient.__call_api\u001b[1;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[0;32m    161\u001b[0m url \u001b[38;5;241m=\u001b[39m build_request_url(\n\u001b[0;32m    162\u001b[0m     config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[0;32m    163\u001b[0m     processed_path_params\u001b[38;5;241m=\u001b[39mpath_params_tuple,\n\u001b[0;32m    164\u001b[0m     resource_path\u001b[38;5;241m=\u001b[39mresource_path,\n\u001b[0;32m    165\u001b[0m     _host\u001b[38;5;241m=\u001b[39m_host,\n\u001b[0;32m    166\u001b[0m )\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;66;03m# perform request and return response\u001b[39;00m\n\u001b[1;32m--> 170\u001b[0m     response_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocessed_query_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocessed_post_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m PineconeApiException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    181\u001b[0m     e\u001b[38;5;241m.\u001b[39mbody \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mbody\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\pytho3\\Lib\\site-packages\\pinecone\\openapi_support\\api_client.py:386\u001b[0m, in \u001b[0;36mApiClient.request\u001b[1;34m(self, method, url, query_params, headers, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrest_client\u001b[38;5;241m.\u001b[39mOPTIONS(\n\u001b[0;32m    377\u001b[0m         url,\n\u001b[0;32m    378\u001b[0m         query_params\u001b[38;5;241m=\u001b[39mquery_params,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    383\u001b[0m         body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    384\u001b[0m     )\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrest_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPOST\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpost_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPUT\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrest_client\u001b[38;5;241m.\u001b[39mPUT(\n\u001b[0;32m    397\u001b[0m         url,\n\u001b[0;32m    398\u001b[0m         query_params\u001b[38;5;241m=\u001b[39mquery_params,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    403\u001b[0m         body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    404\u001b[0m     )\n",
      "File \u001b[1;32md:\\pytho3\\Lib\\site-packages\\pinecone\\openapi_support\\rest_utils.py:146\u001b[0m, in \u001b[0;36mRestClientInterface.POST\u001b[1;34m(self, url, headers, query_params, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mPOST\u001b[39m(\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    138\u001b[0m     url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    144\u001b[0m     _request_timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    145\u001b[0m ):\n\u001b[1;32m--> 146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpost_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\pytho3\\Lib\\site-packages\\pinecone\\openapi_support\\rest_urllib3.py:267\u001b[0m, in \u001b[0;36mUrllib3RestClient.request\u001b[1;34m(self, method, url, query_params, headers, body, post_params, _preload_content, _request_timeout)\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[38;5;66;03m# log response body\u001b[39;00m\n\u001b[0;32m    265\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse body: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, r\u001b[38;5;241m.\u001b[39mdata)\n\u001b[1;32m--> 267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mraise_exceptions_or_return\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\pytho3\\Lib\\site-packages\\pinecone\\openapi_support\\rest_utils.py:49\u001b[0m, in \u001b[0;36mraise_exceptions_or_return\u001b[1;34m(r)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m500\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m599\u001b[39m:\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ServiceException(http_resp\u001b[38;5;241m=\u001b[39mr)\n\u001b[1;32m---> 49\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PineconeApiException(http_resp\u001b[38;5;241m=\u001b[39mr)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[1;31mPineconeApiException\u001b[0m: (400)\nReason: Bad Request\nHTTP response headers: HTTPHeaderDict({'Date': 'Sun, 28 Dec 2025 16:12:42 GMT', 'Content-Type': 'application/json', 'Content-Length': '102', 'Connection': 'keep-alive', 'x-pinecone-request-latency-ms': '1664', 'x-pinecone-request-id': '3479094119580190069', 'x-envoy-upstream-service-time': '32', 'x-pinecone-response-duration-ms': '1666', 'server': 'envoy'})\nHTTP response body: {\"code\":3,\"message\":\"Vector dimension 768 does not match the dimension of the index 384\",\"details\":[]}\n"
     ]
    }
   ],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docstore = PineconeVectorStore.from_documents(\n",
    "    documents=text_chunk,\n",
    "    embedding=embedding_model,\n",
    "    index_name=\"test\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d55003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch= PineconeVectorStore.from_existing_index(\n",
    "    embedding=embedding_model,\n",
    "    index_name=\"test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7161fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimized retrieval strategy with MMR for diversity and relevance balance\n",
    "retriever = docsearch.as_retriever(\n",
    "    search_type=\"mmr\",  # Maximal Marginal Relevance for diverse results\n",
    "    search_kwargs={\n",
    "        \"k\": 8,  # Return top 8 most relevant chunks (reduced from 25 for better focus)\n",
    "        \"fetch_k\": 30,  # Fetch 30 candidates before MMR reranking (reduced from 70)\n",
    "        \"lambda_mult\": 0.7  # Balance between relevance (1.0) and diversity (0.0)\n",
    "    }\n",
    ")\n",
    "\n",
    "# Alternative: Use similarity search with score threshold for high-precision retrieval\n",
    "# retriever = docsearch.as_retriever(\n",
    "#     search_type=\"similarity_score_threshold\",\n",
    "#     search_kwargs={\n",
    "#         \"k\": 8,\n",
    "#         \"score_threshold\": 0.7  # Only return chunks with similarity > 0.7\n",
    "#     }\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba17805",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_classic.chains import create_retrieval_chain\n",
    "from langchain_classic.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are MaBondhu AI, an expert maternal health assistant providing evidence-based prenatal care guidance.\\\\n\\\\n\"\n",
    "    \n",
    "    \"# YOUR MISSION\\\\n\"\n",
    "    \"Deliver safe, accurate, culturally-appropriate maternal health advice for expecting mothers in {language}.\\\\n\\\\n\"\n",
    "    \n",
    "    \"# RESPONSE PROTOCOL\\\\n\"\n",
    "    \"## Emergency Detection (Priority 1)\\\\n\"\n",
    "    \"- Identify danger signs: severe bleeding, severe headache, blurred vision, severe abdominal pain, reduced fetal movement, high fever, seizures, severe swelling\\\\n\"\n",
    "    \"- If detected: Start with '⚠️ EMERGENCY' and recommend IMMEDIATE medical attention\\\\n\"\n",
    "    \"- List nearest action: 'Go to emergency room NOW' or 'Call emergency services'\\\\n\\\\n\"\n",
    "    \n",
    "    \"## Medical Uncertainty (Priority 2)\\\\n\"\n",
    "    \"- If context insufficient or condition complex, state: 'I recommend consulting with a healthcare provider for proper evaluation'\\\\n\"\n",
    "    \"- List specific tests/vitals needed (e.g., blood pressure, ultrasound, blood sugar)\\\\n\\\\n\"\n",
    "    \n",
    "    \"## Standard Guidance (Priority 3)\\\\n\"\n",
    "    \"For routine questions about nutrition, prenatal care, symptoms, lifestyle:\\\\n\"\n",
    "    \"1. **Main Answer**: Provide clear, detailed explanation using retrieved context\\\\n\"\n",
    "    \"2. **Evidence**: Cite sources explicitly (e.g., [WHO Guidelines] or [UNICEF Nutrition Guide])\\\\n\"\n",
    "    \"3. **Actionable Steps**: List 2-3 specific actions with details:\\\\n\"\n",
    "    \"   - What to do (e.g., 'Take 60mg iron supplement daily')\\\\n\"\n",
    "    \"   - When to do it (e.g., 'with meals to reduce nausea')\\\\n\"\n",
    "    \"   - Why it matters (e.g., 'prevents anemia during pregnancy')\\\\n\"\n",
    "    \"4. **Timeline/Schedule**: If relevant, provide checkup schedules or timelines\\\\n\"\n",
    "    \"5. **Safety Note**: Mention any precautions or warning signs to watch\\\\n\\\\n\"\n",
    "    \n",
    "    \"## Information Not Available\\\\n\"\n",
    "    \"- If question outside your knowledge: 'I don't have specific information about this. Please consult with your healthcare provider for accurate guidance.'\\\\n\"\n",
    "    \"- Never make up medical information\\\\n\\\\n\"\n",
    "    \n",
    "    \"# RESPONSE QUALITY STANDARDS\\\\n\"\n",
    "    \"✓ Evidence-based: Use only information from retrieved context\\\\n\"\n",
    "    \"✓ Specific: Provide concrete numbers, dosages, timelines\\\\n\"\n",
    "    \"✓ Empathetic: Use reassuring, supportive language\\\\n\"\n",
    "    \"✓ Cultural: Consider Bangladesh context and local healthcare access\\\\n\"\n",
    "    \"✓ Clear: Write in simple {language} avoiding complex medical jargon\\\\n\"\n",
    "    \"✓ Structured: Use bullet points, numbered lists for readability\\\\n\\\\n\"\n",
    "    \n",
    "    \"# EXAMPLE RESPONSES\\\\n\"\n",
    "    \"Q: 'What foods should I eat during pregnancy?'\\\\n\"\n",
    "    \"A: '**Nutritious Foods for Healthy Pregnancy** [UNICEF Nutrition Guide]\\\\n\\\\n\"\n",
    "    \"Focus on these food groups:\\\\n\"\n",
    "    \"1. **Iron-rich foods**: Red meat, spinach, lentils (prevents anemia)\\\\n\"\n",
    "    \"2. **Calcium sources**: Milk, yogurt, cheese (builds baby's bones)\\\\n\"\n",
    "    \"3. **Folate-rich**: Leafy greens, beans, fortified cereals (prevents birth defects)\\\\n\"\n",
    "    \"4. **Protein**: Eggs, fish, chicken, dal (supports baby's growth)\\\\n\\\\n\"\n",
    "    \"**Action Steps:**\\\\n\"\n",
    "    \"- Eat 3 balanced meals + 2 snacks daily\\\\n\"\n",
    "    \"- Take prenatal vitamin with 400mcg folic acid\\\\n\"\n",
    "    \"- Drink 8-10 glasses of water daily\\\\n\"\n",
    "    \"- Avoid raw/undercooked meat and unpasteurized dairy\\\\n\\\\n\"\n",
    "    \"Next checkup: Discuss any dietary concerns with your doctor.'\\\\n\\\\n\"\n",
    "    \n",
    "    \"# CONTEXT FROM KNOWLEDGE BASE\\\\n\"\n",
    "    \"{context}\\\\n\\\\n\"\n",
    "    \n",
    "    \"# YOUR RESPONSE\\\\n\"\n",
    "    \"Now answer the user's question following the protocol above in {language}. Be thorough yet concise.\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{input}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1cee0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answering_chain = create_stuff_documents_chain(llm, prompt=prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answering_chain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79eec88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query preprocessing function to improve retrieval\n",
    "def preprocess_query(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Enhance user query for better retrieval by:\n",
    "    1. Expanding medical abbreviations\n",
    "    2. Adding context keywords\n",
    "    3. Normalizing terminology\n",
    "    \"\"\"\n",
    "    # Common medical term mappings\n",
    "    term_expansion = {\n",
    "        \"bp\": \"blood pressure\",\n",
    "        \"hb\": \"hemoglobin\",\n",
    "        \"anc\": \"antenatal care\",\n",
    "        \"pnc\": \"postnatal care\",\n",
    "        \"ttv\": \"tetanus toxoid vaccine\",\n",
    "        \"ifa\": \"iron folic acid\",\n",
    "        \"usg\": \"ultrasound\",\n",
    "        \"c-section\": \"cesarean section\",\n",
    "        \"ob-gyn\": \"obstetrician gynecologist\"\n",
    "    }\n",
    "    \n",
    "    query_lower = query.lower()\n",
    "    for abbrev, full_term in term_expansion.items():\n",
    "        if abbrev in query_lower:\n",
    "            query = query.replace(abbrev, full_term)\n",
    "            query = query.replace(abbrev.upper(), full_term)\n",
    "    \n",
    "    # Add pregnancy context if not present\n",
    "    pregnancy_keywords = [\"pregnancy\", \"pregnant\", \"prenatal\", \"antenatal\", \"maternal\", \"expecting\"]\n",
    "    if not any(keyword in query_lower for keyword in pregnancy_keywords):\n",
    "        query = f\"{query} during pregnancy\"\n",
    "    \n",
    "    return query.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa3d8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Response validation and safety check\n",
    "def validate_response(response: dict, query: str) -> dict:\n",
    "    \"\"\"\n",
    "    Add safety checks and response quality validation\n",
    "    \"\"\"\n",
    "    answer = response.get('answer', '')\n",
    "    \n",
    "    # Check for emergency keywords in query or context\n",
    "    emergency_keywords = [\n",
    "        'bleeding', 'blood', 'severe pain', 'headache severe',\n",
    "        'blurred vision', 'seizure', 'convulsion', 'unconscious',\n",
    "        'baby not moving', 'reduced movement', 'high fever',\n",
    "        'water broke', 'contractions', 'severe swelling'\n",
    "    ]\n",
    "    \n",
    "    query_lower = query.lower()\n",
    "    is_emergency = any(keyword in query_lower for keyword in emergency_keywords)\n",
    "    \n",
    "    if is_emergency and '⚠️ EMERGENCY' not in answer and 'EMERGENCY' not in answer:\n",
    "        # Add safety prefix if emergency detected but not in response\n",
    "        answer = (\n",
    "            \"⚠️ IMPORTANT: This may require medical attention. \"\n",
    "            \"If you're experiencing severe symptoms, please contact your healthcare provider immediately.\\n\\n\" \n",
    "            + answer\n",
    "        )\n",
    "        response['answer'] = answer\n",
    "    \n",
    "    # Add disclaimer footer\n",
    "    disclaimer = (\n",
    "        \"\\n\\n---\\n\"\n",
    "        \"ℹ️ *This advice is for informational purposes. \"\n",
    "        \"Always consult your healthcare provider for medical decisions.*\"\n",
    "    )\n",
    "    \n",
    "    if disclaimer not in answer:\n",
    "        response['answer'] = answer + disclaimer\n",
    "    \n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402ffb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, the World Health Organization (WHO) recommendations on antenatal care (ANC) aim to ensure a \"positive pregnancy experience\". While the complete \"Table 1: Summary list of WHO recommendations on antenatal care (ANC) for a positive pregnancy experience\" is referenced as a comprehensive list (Executive summary xi), the full content of this table is not provided in the context.\n",
      "\n",
      "However, specific recommendations and non-recommendations mentioned include:\n",
      "\n",
      "**A positive pregnancy experience is defined as:**\n",
      "*   Maintaining physical and sociocultural normality.\n",
      "*   Maintaining a healthy pregnancy for mother and baby (including preventing and treating risks, illness and death).\n",
      "*   Having an effective transition to positive labour and birth.\n",
      "*   Achieving positive motherhood [WHO page 2].\n",
      "\n",
      "**Specific ANC recommendations and considerations mentioned:**\n",
      "\n",
      "1.  **Counselling about healthy eating and keeping physically active during pregnancy** is recommended for pregnant women to stay healthy [WHO Executive summary xi, A.1.1].\n",
      "2.  **Restricting caffeine intake** is mentioned as an implementation consideration for counselling during ANC [WHO page 146, A.10.a].\n",
      "3.  **Routine antenatal cardiotocography (CTG)** is **not recommended**. Health-care providers should omit this from practice due to a lack of evidence [WHO page 148, B.2.3].\n",
      "4.  **Routine ultrasound scans** are mentioned under maternal and fetal assessment (B.2.4), with considerations for health system level regarding the number and capacity of facilities [WHO page 148]. While the context notes that a lack of modern technology like ultrasound can discourage women from attending ANC in some low- and middle-income countries, a specific blanket recommendation for *routine* scans across all settings is not explicitly detailed in the provided snippets of Table 1.\n",
      "\n",
      "**Next Steps:**\n",
      "*   **Maintain a healthy lifestyle:** Engage in counselling about healthy eating and keeping physically active throughout your pregnancy.\n",
      "*   **Consider caffeine intake:** Discuss caffeine restriction with your healthcare provider if it's typically part of your diet.\n",
      "\n",
      "---\n",
      "\n",
      "প্রদত্ত তথ্যের উপর ভিত্তি করে, ইতিবাচক গর্ভাবস্থার অভিজ্ঞতা নিশ্চিত করার জন্য বিশ্ব স্বাস্থ্য সংস্থা (WHO) এর প্রসবপূর্ব যত্নের (ANC) সুপারিশমালা নিম্নলিখিত বিষয়গুলি তুলে ধরেছে:\n",
      "\n",
      "একটি \"ইতিবাচক গর্ভাবস্থার অভিজ্ঞতা\" এর সংজ্ঞা:\n",
      "*   শারীরিক এবং সামাজিক-সাংস্কৃতিক স্বাভাবিকতা বজায় রাখা।\n",
      "*   মা ও শিশুর জন্য একটি সুস্থ গর্ভাবস্থা বজায় রাখা (ঝুঁকি, অসুস্থতা এবং মৃত্যু প্রতিরোধ ও চিকিৎসাসহ)।\n",
      "*   একটি ইতিবাচক প্রসব ও জন্মদানে কার্যকরভাবে উত্তীর্ণ হওয়া।\n",
      "*   ইতিবাচক মাতৃত্ব অর্জন করা [WHO পৃষ্ঠা 2]।\n",
      "\n",
      "**সুনির্দিষ্ট প্রসবপূর্ব যত্ন (ANC) সুপারিশ এবং বিবেচ্য বিষয়সমূহ:**\n",
      "\n",
      "1.  **গর্ভাবস্থায় স্বাস্থ্যকর খাদ্যাভ্যাস এবং শারীরিকভাবে সক্রিয় থাকার বিষয়ে পরামর্শ** গর্ভবতী মহিলাদের সুস্থ থাকার জন্য সুপারিশ করা হয় [WHO কার্যনির্বাহী সারাংশ xi, A.1.1]।\n",
      "2.  **ক্যাফেইন গ্রহণ সীমিত করা** প্রসবপূর্ব যত্নের সময় পরামর্শের জন্য একটি বাস্তবায়ন বিবেচনা হিসাবে উল্লেখ করা হয়েছে [WHO পৃষ্ঠা 146, A.10.a]।\n",
      "3.  **নিয়মিত প্রসবপূর্ব কার্ডিওটোকোগ্রাফি (CTG)** **সুপারিশ করা হয় না**। প্রমাণের অভাবে স্বাস্থ্যসেবা প্রদানকারীদের এটি অনুশীলন থেকে বাদ দেওয়া উচিত [WHO পৃষ্ঠা 148, B.2.3]।\n",
      "4.  **নিয়মিত আল্ট্রাসাউন্ড স্ক্যান** মাতৃ ও ভ্রূণ মূল্যায়নের অধীনে (B.2.4) উল্লেখ করা হয়েছে, যেখানে সুবিধার সংখ্যা এবং ক্ষমতা সম্পর্কিত স্বাস্থ্য ব্যবস্থার স্তরের জন্য বিবেচনা রয়েছে [WHO পৃষ্ঠা 148]। যদিও প্রেক্ষাপটে উল্লেখ করা হয়েছে যে আল্ট্রাসাউন্ড সরঞ্জামের মতো আধুনিক প্রযুক্তির অভাব কিছু নিম্ন ও মধ্যম আয়ের দেশে মহিলাদের ANC-তে আসতে নিরুৎসাহিত করতে পারে, তবুও টেবিল 1 এর প্রদত্ত অংশগুলিতে সমস্ত সেটিংসে *নিয়মিত* স্ক্যানের জন্য একটি নির্দিষ্ট ব্যাপক সুপারিশ স্পষ্টভাবে বিস্তারিত করা হয়নি।\n",
      "\n",
      "**পরবর্তী পদক্ষেপ:**\n",
      "*   **সুস্থ জীবনযাপন বজায় রাখুন:** আপনার গর্ভাবস্থায় স্বাস্থ্যকর খাদ্যাভ্যাস এবং শারীরিকভাবে সক্রিয় থাকার বিষয়ে পরামর্শ গ্রহণ করুন।\n",
      "*   **ক্যাফেইন গ্রহণের বিষয়ে বিবেচনা করুন:** যদি ক্যাফেইন আপনার খাদ্যাভ্যাসের অংশ হয়ে থাকে তবে আপনার স্বাস্থ্যসেবা প্রদানকারীর সাথে ক্যাফেইন সীমিত করার বিষয়ে আলোচনা করুন।\n"
     ]
    }
   ],
   "source": [
    "# Enhanced query interface with preprocessing and validation\n",
    "\n",
    "print(\"🤰 MaBondhu AI - Your Maternal Health Assistant\")\n",
    "print(\"=\"*50)\n",
    "inp = input(\"\\nEnter your question: \")\n",
    "language_choice = input(\"Language (English/Bengali): \").strip() or \"English\"\n",
    "\n",
    "# Preprocess query for better retrieval\n",
    "processed_query = preprocess_query(inp)\n",
    "print(f\"\\n🔍 Processing: {processed_query}...\\n\")\n",
    "\n",
    "# Get response\n",
    "response = rag_chain.invoke({\n",
    "    \"input\": processed_query,\n",
    "    \"language\": language_choice\n",
    "})\n",
    "\n",
    "# Validate and enhance response\n",
    "validated_response = validate_response(response, inp)\n",
    "\n",
    "# Display answer\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"📋 MaBondhu AI Response:\")\n",
    "print(\"=\"*50)\n",
    "print(validated_response['answer'])\n",
    "\n",
    "# Optionally show source documents\n",
    "if 'context' in validated_response:\n",
    "    print(\"\\n📚 Sources Used:\")\n",
    "    sources = set()\n",
    "    for doc in validated_response.get('context', []):\n",
    "        source = doc.metadata.get('source', 'Unknown')\n",
    "        doc_type = doc.metadata.get('document_type', '')\n",
    "        sources.add(f\"- {source} ({doc_type})\")\n",
    "    for source in sorted(sources):\n",
    "        print(source)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
